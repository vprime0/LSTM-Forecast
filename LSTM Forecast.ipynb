{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bbff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import requests\n",
    "import datetime\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from tensorflow.keras.losses import Huber\n",
    "from keras.optimizers import Nadam\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5a52f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query='''            WITH table1 as \n",
    "(\n",
    "SELECT  DATEADD(WEEK,DATEDIFF(WEEK,0, th.[TranDate]),0) AS DateWeek,p.[Category],p.[Class],p.[StockCode],\n",
    "p.[Description],tl.[Quantity]\n",
    "From [PowerBI].[dbo].[TransactionLine] tl \n",
    "LEFT JOIN [PowerBI].[dbo].[Subsidiary] s ON tl.SubsidiaryId = s.[SubsidiaryId] \n",
    "LEFT JOIN [PowerBI].[dbo].[TransactionHeader] th ON tl.[TransactionId]=th.[TransactionId]\n",
    "LEFT JOIN [PowerBI].[dbo].[Product] p ON tl.[ProductId] =p.[ProductId]\n",
    "LEFT JOIN [PowerBI].[dbo].[ItemInventory] i ON i.[ProductId]= p.ProductId \n",
    "\n",
    "WHERE --p.[Status] IN ('Current', 'Promo','Clearance') \n",
    "p.[StockCode] = 'BW60057GB'\n",
    "AND s.Name='Wilton Bradley Limited' \n",
    "AND p.[Class] IS NOT NULL \n",
    "AND p.[Category] IS NOT NULL \n",
    "AND  tl.[GlId] =54\n",
    "AND tl.TransactionType IN ('Cash Sale', 'Credit Memo','Invoice')\n",
    "\n",
    ")\n",
    "\n",
    "SELECT  CAST([DateWeek] AS Date) AS DateWeek,[Category],[Class],[StockCode],[Description], SUM([Quantity]) AS Quantity\n",
    "FROM table1  \n",
    "GROUP BY [StockCode], [DateWeek], [Description],[Category],[Class]\n",
    "ORDER BY [DateWeek] ASC\n",
    "\n",
    "               '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc239a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine=sqlalchemy.create_engine(\"mssql://@192.168.35.102/PowerBi?driver=SQL Server\")\n",
    "connection=engine.connect()\n",
    "result=connection.execute(sqlalchemy.text(query))\n",
    "\n",
    "data=[row for row in result]\n",
    "connection.close()\n",
    "\n",
    "df=pd.DataFrame(data)\n",
    "df[\"DateWeek\"]=pd.to_datetime(df[\"DateWeek\"])\n",
    "df=df[df[\"DateWeek\"]<=datetime.datetime.now()]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0e9c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "last_train_date_file = 'S:\\sales office\\Vishnu\\Forcast for inventory managment\\LSTM_Models\\Bestway\\lastet_train_date\\last_train_date.json'\n",
    "\n",
    "def get_last_train_date():\n",
    "    try:\n",
    "        with open(last_train_date_file, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            return pd.to_datetime(data['last_train_date'])\n",
    "    except FileNotFoundError:\n",
    "        print(\"Last train date file not found.\")\n",
    "        return None\n",
    "\n",
    "def update_last_train_date(date):\n",
    "    with open(last_train_date_file, 'w') as file:\n",
    "        json.dump({'last_train_date': str(date)}, file)\n",
    "\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "latest_date = df[\"DateWeek\"].max()\n",
    "\n",
    "# Display the last training date\n",
    "print(\"Last training date:\", get_last_train_date())\n",
    "\n",
    "# Update the last training date with the latest date from your DataFrame\n",
    "update_last_train_date(latest_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b1e4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting covid data\n",
    "df_covid=pd.read_csv(\"S:/sales office/Vishnu/Forcast for inventory managment/covid-data.csv\")\n",
    "# filtering onlu uk covid data\n",
    "df_covid[df_covid[\"location\"]==\"United Kingdom\"][[\"date\",\"new_cases\"]].sort_values(by=\"date\")\n",
    "\n",
    "df_cov=df_covid[df_covid[\"location\"]==\"United Kingdom\"][[\"date\",\"new_cases\"]]\n",
    "df_cov[\"date\"]=pd.to_datetime(df_cov[\"date\"], format=\"%d/%m/%Y\")\n",
    "df_cov.set_index(\"date\", inplace=True)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "df_cov=df_cov.resample('W-Mon').sum()\n",
    "df_cov.reset_index(inplace=True)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "initial =pd.Timestamp(\"2020-03-30\")\n",
    "last=pd.Timestamp(\"2021-04-30\")\n",
    "\n",
    "df_cov[\"cases\"]= df_cov[\"date\"].apply(lambda x: 1 if initial <=x <=last else 0)\n",
    "\n",
    "df_cov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e4a538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating lags\n",
    "def create_lag(df):\n",
    "    number_of_lags=1\n",
    "    '''\n",
    "    for lag in range(1,number_of_lags+1):\n",
    "        df[f\"Qty_lag{lag}\"]=df[\"Quantity\"].shift(lag)\n",
    "    '''\n",
    "        \n",
    "    for lag in range(1, number_of_lags+1):\n",
    "        df[f\"Qty_diff_lag{lag}\"]=df[\"Quantity\"].shift(lag)\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e970bc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a week list starting from 2018-12-31\n",
    "start_date = dt.datetime(2018, 12, 31)\n",
    "week_dates = []\n",
    "today= dt.datetime.now()\n",
    "\n",
    "while start_date<= today:\n",
    "    week_dates.append(start_date.strftime(\"%Y-%m-%d\"))\n",
    "    start_date+=dt.timedelta(days=7)\n",
    "\n",
    "week_dates=pd.DataFrame(week_dates, columns=[\"Week\"])\n",
    "week_dates[\"Week\"]=pd.to_datetime(week_dates[\"Week\"])\n",
    "week_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94735731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "def remove_outliers(df, col):\n",
    "    q1=df[col].quantile(0.25)\n",
    "    q3=df[col].quantile(0.75)\n",
    "    \n",
    "    iqr=q3-q1\n",
    "    \n",
    "    lb=q1-1.5*iqr\n",
    "    ub=q3+1.5*iqr\n",
    "    \n",
    "    df1=df[(df[col]<=ub ) &(df[col]>=lb) ]\n",
    "    \n",
    "    return df1\n",
    "\n",
    "def cap_outliers(df, col, cap=95):\n",
    "    ul=df[col].quantile(cap/100)\n",
    "    ll=df[col].quantile((100-cap)/100)\n",
    "    \n",
    "    df[col]=np.where(df[col]>ul, ul, df[col])\n",
    "    df[col]=np.where(df[col]<ll, ll, df[col] )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd87a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "stock_predictions={}\n",
    "\n",
    "total_stocks=len(df_bestway[\"StockCode\"].unique())\n",
    "processed_stock=0\n",
    "\n",
    "model_dir=\"S:\\sales office\\Vishnu\\Forcast for inventory managment\\LSTM_Models\\Bestway\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "for code in tqdm(df_bestway[\"StockCode\"].unique()):\n",
    "    \n",
    "    processed_stock+=1\n",
    "    percent_complete=(processed_stock/total_stocks)*100\n",
    "    \n",
    "    print(\"/n/nStokCode : \",code)\n",
    "    print(\"Processed Stocks : \",processed_stock)\n",
    "    print(\"Percent Completed : \", percent_complete)\n",
    "    single_stock_data=df_bestway[df_bestway[\"StockCode\"].isin([code])].drop(columns=[\"Category\",\"Class\",\"Description\"])\n",
    "\n",
    "    single_stock_data[\"DateWeek\"]=pd.to_datetime(single_stock_data[\"DateWeek\"])\n",
    "\n",
    "    single_stock_data=single_stock_data.merge(week_dates, left_on=\"DateWeek\", right_on=\"Week\", how=\"right\")\n",
    "    single_stock_data[\"StockCode\"].ffill(axis=0, inplace=True)\n",
    "    single_stock_data=single_stock_data[single_stock_data[\"StockCode\"].notna()]\n",
    "    single_stock_data.drop(\"DateWeek\",axis=1, inplace=True)\n",
    "    single_stock_data[\"Quantity\"].fillna(0,inplace=True)\n",
    "    single_stock_data=single_stock_data.merge(df_cov, how=\"left\", left_on=\"Week\", right_on=\"date\")\n",
    "    single_stock_data.drop([\"date\",\"date\",\"new_cases\"],axis=1, inplace=True)\n",
    "    single_stock_data[\"cases\"].fillna(0, inplace=True)\n",
    "    single_stock_data.head()\n",
    "    \n",
    "    values=single_stock_data[[\"Quantity\",\"cases\"]]\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_values = scaler.fit_transform(values)\n",
    "\n",
    "    #Create Sequence\n",
    "    n_input =7 # for example, predicting using 8 weeks \n",
    "    n_features = 2  # we are now considering two features\n",
    "    samples = len(scaled_values) - n_input\n",
    "\n",
    "    inputs, outputs = [], []\n",
    "    for i in range(samples):\n",
    "        input_data = scaled_values[i:(i + n_input)]\n",
    "        output_data = scaled_values[i + n_input, 0]  # We predict only the 'Quantity' column\n",
    "        inputs.append(input_data)\n",
    "        outputs.append(output_data)\n",
    "\n",
    "\n",
    "    inputs_array = np.array(inputs).reshape(len(inputs), n_input, n_features)\n",
    "    outputs_array = np.array(outputs)\n",
    "\n",
    "    #Define the percentage of data you want for testing\n",
    "    test_pct=0.20\n",
    "\n",
    "    #Calculate the number of sample for testing\n",
    "    #num_test_samples=int(inputs_array.shape[0]*test_pct)\n",
    "    num_test_samples=26\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    inputs_train=inputs_array[:-num_test_samples]\n",
    "    outputs_train=outputs_array[:-num_test_samples]\n",
    "    inputs_test= inputs_array[-num_test_samples:]\n",
    "    outputs_test=outputs_array[-num_test_samples:]\n",
    "\n",
    "\n",
    "    #LSTM Model\n",
    "    model=Sequential()\n",
    "    model.add(LSTM(1000, activation=PReLU(), input_shape=(n_input, n_features), return_sequences=False))\n",
    "    #model.add(Dropout(0.3))\n",
    "    #model.add(LSTM(200, activation=\"leaky_relu\", return_sequences=True))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(LSTM(100, activation=\"leaky_relu\", return_sequences=True))\n",
    "    #model.add(LSTM(200, activation=\"leaky_relu\", return_sequences=True))\n",
    "    #model.add(LSTM(50, activation=\"leaky_relu\", return_sequences=False))\n",
    "    #model.add(LSTM(30, activation=\"relu\", return_sequences=False))\n",
    "\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "\n",
    "    optimizer=SGD(lr=0.001, momentum=0.9)\n",
    "    #optimizer = Nadam(learning_rate=0.01)\n",
    "    #optimizer = RMSprop(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss=\"mae\")\n",
    "\n",
    "    # automatically stop training when the model's performance on the validation set starts to degrade\n",
    "    #early_stopping=EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(inputs_train, outputs_train, epochs=3000, validation_split=0.05, verbose=1)#callbacks=[early_stopping])\n",
    "    \n",
    "    model_filename=f\"LSTM_{code}.h5\"\n",
    "    model.save(os.path.join(model_dir, model_filename))\n",
    "    print(f\"Model for StockCode {code} saved successfully\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2d8b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5b0efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b466e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69c2f48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93ed8bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfce6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc598da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1946a1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
